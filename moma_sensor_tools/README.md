# moma_sensor_tools

Collection of utilities related to sensor used in the moma demos.


Currently this package contains utilities to use and calibration of the _rokubimini_ force torque sensor.
Calibration is performed sending the robot to various target poses and estimating, assuming that the wrench is only generated by the payload, its properties (COM, weights and biases).

## Calibration

### File system organisation

All calibration files are kept locally on the PC that has the camera attached to it. The default (recommended) path to keep calibration files is `~/calibration/...`. This avoids confusion and makes a consistent setup, such that everyone knows where to expect calibration files to be located. Additionally, a permanent copy of important calibration files can be kept in the MoMa repo under `$(moma_sensor_tools)/config/...`.

### Intrinsic calibration routine

The calibration of the intrinsics is done using the [`camera_calibration`](http://wiki.ros.org/camera_calibration) package, using a pinhole model.

1. Run the RealSense camera stream, for example by
   ```bash
   roslaunch moma_sensor_tools calibration.launch operator_pc:=false
   ```
2. Run the intrinsic calibration
   ```bash
   rosrun camera_calibration cameracalibrator.py --size 7x6 --square 0.07 image:=/hand_eye/color/image_raw camera:=/hand_eye/color --no-service-check
   ```

The calibration generates a file `/tmp/calibrationdata.tar.gz` which needs to be extracted. The contained `ost.yaml` file needs to be moved to `~/calibration/camera_calibration.yaml`. If you want to keep it permanently for other users of the MoMa repo, also make a copy of it to `$(moma_sensor_tools)/config/camera_calibration/(camera-name/serialnum/identifier).yaml`.

### Hand-eye calibration routine

The hand-eye calibration can be performed using the [easy_hand_eye](https://github.com/IFL-CAMP/easy_handeye) package in combination with moveit and the [easy_hand_eye rqt gui](https://github.com/IFL-CAMP/easy_handeye/tree/master/rqt_easy_handeye). Here we provide some launch and config files which should be the process easy to setup and reproduce for the panda robot. For more information, refer to the documentation of the calibration packages.  

1. Launch the panda robot on the robot computer with moveit enabled:
    ```bash
    roslaunch moma_robot robot_pc.launch moveit:=true
    ```
2. In a ROS-networked operator PC, run the calibration routine:
    ```bash
    roslaunch moma_sensor_tools calibration.launch 
    ```
    This will launch the realsese camera driver, and a sample collection gui that will allow to alternate between different camera viewpoints and collect apriltag marker poses. The calibration routine also launches the apriltag detector which reads the specific aprilag configuration from this [config file](config/handeye_calibration/apriltags.yaml). Make sure that the information in this file reflects the apriltag you are currently using.

    2.1 If you want to run the camera node and the operator node on separate PCs, use
    ```bash
    roslaunch moma_sensor_tools calibration.launch operator_pc:=false
    ```
   and
   ```bash
    roslaunch moma_sensor_tools calibration.launch camera_pc:=false
    ```
4. Once the calibration is done, click on save and the new calibration config will be generated in the folder `~/.ros/easy_hand_eye`. For usage, the default local path where the file is expected is `~/calibration/handeye_calibration.yaml`. Please move the file to this location immediately to avoid confusion. If you want to keep it permanently, also make a copy of it to `$(moma_sensor_tools)/config/handeye_calibration/(robot-application-name/configuration-name).yaml`.

To use the newly generated calibration transform, launch:
```bash
roslaunch moma_sensor_tools publish_calibration.launch calibration_file:=<path to calibration file>
```
